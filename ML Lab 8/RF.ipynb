{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.21.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (0.13.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.63\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset (modify path if needed)\n",
    "df = pd.read_csv(\"sampled_dataset.csv\", encoding='latin-1', header=None, usecols=[0, 5], names=['target', 'text'])\n",
    "\n",
    "# Convert sentiment labels (0 = negative, 2 = neutral, 4 = positive)\n",
    "df['target'] = df['target'].replace({0: 'Negative', 2: 'Neutral', 4: 'Positive'})\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters & numbers\n",
    "    text = text.lower().strip()  # Convert to lowercase and trim spaces\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords.words('english'))  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Convert text to numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Use top 5000 words\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['target']\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train RandomForestClassifier utilizing all CPU cores\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=10, n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      "The sentiment of the input text 'hello im fine' is: Positive (4)\n",
      "The sentiment of the input text 'very very dangerous' is: Positive (4)\n"
     ]
    }
   ],
   "source": [
    "input_text1 = \"hello im fine\"\n",
    "input_text2 = \"very very dangerous\"\n",
    "\n",
    "# Preprocess both input texts\n",
    "input_text1_processed = preprocess_text(input_text1)\n",
    "input_text2_processed = preprocess_text(input_text2)\n",
    "\n",
    "# Convert the input texts to numerical features using the same TF-IDF vectorizer\n",
    "input_vector1 = vectorizer.transform([input_text1_processed])\n",
    "input_vector2 = vectorizer.transform([input_text2_processed])\n",
    "\n",
    "# Predict the sentiment for both inputs\n",
    "predicted_sentiment1 = clf.predict(input_vector1)\n",
    "predicted_sentiment2 = clf.predict(input_vector2)\n",
    "\n",
    "# Map sentiment values to labels\n",
    "sentiment_map = {\n",
    "    'Negative': 0,\n",
    "    'Neutral': 2,\n",
    "    'Positive': 4\n",
    "}\n",
    "\n",
    "# Get the predicted sentiment labels\n",
    "predicted_label1 = predicted_sentiment1[0]\n",
    "predicted_label2 = predicted_sentiment2[0]\n",
    "\n",
    "# Function to print sentiment with explanation\n",
    "def print_sentiment(input_text, predicted_label):\n",
    "    if predicted_label == 'Negative':\n",
    "        print(f\"The sentiment of the input text '{input_text}' is: Negative (0)\")\n",
    "    elif predicted_label == 'Neutral':\n",
    "        print(f\"The sentiment of the input text '{input_text}' is: Neutral (2)\")\n",
    "    else:\n",
    "        print(f\"The sentiment of the input text '{input_text}' is: Positive (4)\")\n",
    "\n",
    "# Print the result for both input texts\n",
    "print(\"Hi\")\n",
    "print_sentiment(input_text1, predicted_label1)\n",
    "print_sentiment(input_text2, predicted_label2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8966365e1e1c555ff681e829c08a5e6730b1f6b1b4c2abfa0ea1145e98ff3d77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
